{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_code_CNN+LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQXxz_VPAgob"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import string\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "filename=\"2l_labeled.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgfsqwz2As-1"
      },
      "source": [
        "\n",
        "f=open(filename,\"r\",encoding=\"utf8\")\n",
        "ids=[]\n",
        "x=[]\n",
        "cats=[]\n",
        "for line in f:\n",
        "    fileid,review,cat=line.split(',')\n",
        "    ids.append(fileid)\n",
        "    x.append(review)\n",
        "    if cat==\"pos\\n\":\n",
        "        cats.append(1)\n",
        "    elif cat==\"neg\\n\":\n",
        "        cats.append(0)\n",
        "y=cats\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo03a5r0Axv3"
      },
      "source": [
        "def clean_str(string):\n",
        "    string = re.sub(r\"\\\\\", \"\", string)    \n",
        "    string = re.sub(r\"\\'\", \"\", string)    \n",
        "    string = re.sub(r\"\\\"\", \"\", string)    \n",
        "    return string.strip().lower()\n",
        "X=[]\n",
        "for i in x:\n",
        "    X.append(clean_str(i))\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(X)\n",
        "xx=[]\n",
        "for review in X:\n",
        "    translator=review.maketrans(\"\",\"\",string.punctuation)\n",
        "    xx.append(review.translate(translator))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xx, y, test_size=0.1)\n",
        "xtrain= tokenizer.texts_to_sequences(x_train)\n",
        "xtest= tokenizer.texts_to_sequences(x_test)\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "maxlen=1000\n",
        "xtrain=pad_sequences(xtrain,padding='pre', maxlen=maxlen)\n",
        "xtest=pad_sequences(xtest,padding='pre', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HYd5gP0A9xa"
      },
      "source": [
        "filename=\"glove.txt\"\n",
        "embeddings_index = {}\n",
        "f=open(filename,\"r\",encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "EMBEDDING_DIM=100\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P_r7-VlBbf8"
      },
      "source": [
        "# CNN + LSTM\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(layers.Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=True))\n",
        "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(64, 5, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "\n",
        "model.add(layers.LSTM(units=50,return_sequences=True))\n",
        "model.add(layers.LSTM(units=10))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(8))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n",
        "     metrics=['accuracy'])\n",
        "model.fit(xtrain,y_train, epochs=10, batch_size=128, verbose=2)\n",
        "\n",
        "loss,acc=model.evaluate(xtest,y_test)\n",
        "print(\"Test accuracy:\",acc)\n",
        "l=(model.predict(xtest))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBYVZzFWBugc"
      },
      "source": [
        "# GUI with a blank slot to enter review and get classification\n",
        "\n",
        "\n",
        "def clicked():\n",
        "    global text\n",
        "    X=text.get()\n",
        "    text2=[]\n",
        "    text3=[]\n",
        "    text4=[]\n",
        "\n",
        "    translator=X.maketrans(\"\",\"\",string.punctuation)\n",
        "    text1=(X.translate(translator))\n",
        "\n",
        "    result= re.sub(r'\\d+', '', text1)\n",
        "    text2.append(result)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "    tokenizer.fit_on_texts(text2)\n",
        "    maxlen=1000\n",
        "    text3=(tokenizer.texts_to_sequences(text2))\n",
        "    text4=pad_sequences(text3,padding='pre', maxlen=maxlen)\n",
        "    p=model.predict(text4)\n",
        "    print(p)\n",
        "    if np.round(p[0])==0:\n",
        "        label_2.configure(text=\"neg\")\n",
        "    elif np.round(p[0])==1:\n",
        "        label_2.configure(text=\"pos\")\n",
        "    \n",
        "   \n",
        "       \n",
        "from tkinter.ttk import *\n",
        "from tkinter import *\n",
        "root=Tk()\n",
        "root.title(\"Sentiment Analysis\")\n",
        "root.geometry('500x250')\n",
        "topframe=Frame(root)\n",
        "topframe.pack()\n",
        "label_1 = Label(topframe,text=\"review_text\")\n",
        "label_1.pack(side=LEFT)\n",
        "text = Entry(topframe)\n",
        "text.pack(fill=X)\n",
        "text.focus_set()\n",
        "bottomframe=Frame(root)\n",
        "bottomframe.pack(side=BOTTOM)\n",
        "button = Button(bottomframe,text=\"Submit\", command=clicked)\n",
        "button.pack()\n",
        "\n",
        "label_2 = Label(bottomframe,text=\"category\")\n",
        "label_2.pack(side=LEFT)\n",
        "\n",
        "\n",
        "root.mainloop()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}